#!/bin/bash
#SBATCH -J jetto-mobo
#SBATCH -A UKAEA-AP002-GPU
#SBATCH -p ampere
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=12
#SBATCH --time=24:00:00
#SBATCH --mail-type=ALL

unset OMP_NUM_THREADS

echo "JETTO-MOBO"
echo "=========="
echo "JobID: $SLURM_JOB_ID"

# Set up environment
. /etc/profile.d/modules.sh
module purge
module load rhel8/default-amp
module load miniconda/3
source /home/tab53/.bashrc
conda activate jetto-mobo

# Set correct path for torch libraries
LD_LIBRARY_PATH=$CONDA_PREFIX/lib/python3.10/site-packages/nvidia/cublas/lib/:$LD_LIBRARY_PATH

# Directory structure
cd /home/tab53/rds/rds-ukaea-ap002-mOlK9qn0PlQ/tab53/jetto-mobo
OUTPUT_DIR="data/mobo/ga_piecewise_linear"

# Save command as a variable, using 'here document' syntax
read -r -d '' COMMAND <<- EOM
    $CONDA_PREFIX/bin/python src/jetto_mobo/main.py \
    --output_dir $OUTPUT_DIR \
    --n_bayesopt_steps 10 \
    --batch_size 5 \
    --jetto_timelimit 10400 \
    --value_function vector \
    --jetto_fail_value 0 \
    --ecrh_function ga_piecewise_linear
EOM

# Resume if target directory exists
if [ -d "$OUTPUT_DIR" ]; then
    COMMAND="$COMMAND --resume"
fi

# Execute
echo "Executing command: $COMMAND"
$COMMAND
